<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>機械学習により金銀滓自動仕訳</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
  <style>
    body { display:flex; flex-direction:column; align-items:center; justify-content:flex-start; font-family: Arial, sans-serif; margin:0; padding:16px; background:#f4f4f4; }
    h1 { margin: 12px 0 8px; font-size: 1.6em; text-align:center; }
    video { width: 90vw; height: 90vw; max-width: 400px; max-height: 400px; border: 3px solid #333; border-radius: 10px; object-fit: cover; background:#111; }
    #result { font-size: 1.4em; margin-top: 12px; font-weight: bold; }
    .panel { width: 90vw; max-width: 400px; background:#fff; border:1px solid #e5e7eb; border-radius:10px; padding:12px; margin-top:12px; }
    .topline { display:flex; justify-content:space-between; align-items:center; gap:8px; }
    .badge { display:inline-block; padding:2px 8px; border-radius:999px; background:#f3f4f6; font-size:12px; }
    .row { display:flex; justify-content:space-between; padding:6px 8px; border-radius:8px; }
    .row + .row { margin-top: 6px; }
    .row.best { font-weight:800; color:#065f46; background:#ecfdf5; }
    .muted { color:#6b7280; font-size:12px; }
    .controls { margin-top:8px; display:flex; gap:8px; }
    .controls > button { padding:8px 12px; border-radius:8px; border:1px solid #d1d5db; background:#fff; cursor:pointer; }
    #err { color:#b91c1c; white-space: pre-wrap; margin-top:6px; font-size:12px; }
  </style>
</head>
<body>
  <h1>機械学習により金銀滓自動仕訳</h1>
  <video id="webcam" autoplay playsinline muted></video>
  <p id="result">少しお待ちください～</p>

  <div class="panel">
    <div class="topline">
      <strong>予測結果</strong>
      <span class="badge" id="backend">backend: …</span>
    </div>
    <div id="predictions"></div>
    <div class="controls">
      <button id="startBtn">開始</button>
      <button id="stopBtn">停止</button>
    </div>
    <div class="muted" id="status"></div>
    <div id="err"></div>
  </div>

  <script>
    // ====== CONFIG (adjust these) ======
    const MODEL_URL = 'tfjs_model/model.json';                   // ← your model path
    const CLASS_LABELS = ['Big Lot', 'C Press', 'Snyders'];      // ← your classes (order MUST match training)
    const INPUT_SIZE = 224;                                      // ← must match your model input

    // Keep EXACT behavior (no conversion). If your training actually used /255 or BGR, flip these:
    const DIVIDE_BY_255 = false;   // set true ONLY if you trained with inputs scaled to 0–1
    const RGB_TO_BGR   = false;    // set true ONLY if you trained with BGR channel order (e.g., OpenCV)

    let model, video, running = false, frame = 0;

    // ====== Backend selection ======
    async function selectBackend() {
      try { await tf.setBackend('webgl'); } catch (_) {}
      if (tf.getBackend() !== 'webgl') {
        try { await tf.setBackend('wasm'); } catch (_) {}
      }
      await tf.ready();
      document.getElementById('backend').textContent = `backend: ${tf.getBackend()}`;
    }

    // ====== Camera ======
    async function setupCamera() {
      video = document.getElementById('webcam');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'environment' }, audio: false
      });
      video.srcObject = stream;
      await new Promise(res => (video.onloadedmetadata = () => res()));
      await video.play();
      return video;
    }

    // ====== Preprocess (match your previous approach) ======
    // fromPixels(video) -> resizeNearestNeighbor -> toFloat()
    // Optional: channel swap or /255 if you toggle the flags above.
    function preprocess(video) {
      return tf.tidy(() => {
        let img = tf.browser.fromPixels(video); // [H,W,3] uint8 RGB
        img = tf.image.resizeNearestNeighbor(img, [INPUT_SIZE, INPUT_SIZE], true);
        let f = img.toFloat();                  // [H,W,3] float32 0..255

        if (RGB_TO_BGR) f = f.reverse(-1);     // swap channels if trained with BGR
        if (DIVIDE_BY_255) f = f.div(255.0);   // enable only if training did /255

        return f.expandDims(0);                // [1,H,W,3]
      });
    }

    // ====== RAW OUTPUT (no softmax/normalization) ======
    async function getRawOutputs(tensorOrArray) {
      const t = Array.isArray(tensorOrArray) ? tensorOrArray[0] : tensorOrArray; // [1,C] or [C]
      const flat = t.rank === 2 ? t.squeeze([0]) : t; // [C]
      const arr = await flat.data();                  // raw numbers as-is
      if (t !== flat) flat.dispose();
      return arr;
    }

    // ====== Render (vertical, top = green bold) ======
    function renderPredictions(values) {
      const items = CLASS_LABELS.map((label, i) => ({ label, v: values[i] ?? 0 }));
      let bestIdx = 0, bestVal = -Infinity;
      for (let i = 0; i < items.length; i++) if (items[i].v > bestVal) { bestVal = items[i].v; bestIdx = i; }

      // Visualizing as “×100%” to keep your UI look; this does NOT change the calculation.
      document.getElementById('result').textContent =
        `${items[bestIdx].label}（${(items[bestIdx].v * 100).toFixed(1)}%）`;

      const predsEl = document.getElementById('predictions');
      predsEl.innerHTML = items.map((it, i) => `
        <div class="row ${i === bestIdx ? 'best' : ''}">
          <div>${it.label}</div>
          <div>${(it.v * 100).toFixed(1)}%</div>
        </div>
      `).join('');
    }

    // ====== Load/Warmup ======
    async function warmup() {
      tf.tidy(() => {
        const z = tf.zeros([1, INPUT_SIZE, INPUT_SIZE, 3]);
        const y = model.predict(z);
        if (Array.isArray(y)) y.forEach(t => t.dispose()); else y.dispose?.();
      });
    }

    async function loadModel() {
      model = await tf.loadLayersModel(MODEL_URL);
      await warmup();
    }

    // ====== Loop ======
    async function loop() {
      if (!running) return;
      await tf.nextFrame();
      frame++;

      try {
        const input = preprocess(video);
        let out = model.predict(input);
        const values = await getRawOutputs(out); // RAW — no conversion
        input.dispose();
        if (Array.isArray(out)) out.forEach(t => t.dispose()); else out.dispose?.();

        if (frame % 2 === 0) renderPredictions(values);
      } catch (e) {
        console.error(e);
        document.getElementById('err').textContent = String(e?.message || e);
      }
      requestAnimationFrame(loop);
    }

    // ====== Controls & Cleanup ======
    function stop() {
      running = false;
      document.getElementById('status').textContent = '停止中';
    }

    async function start() {
      document.getElementById('err').textContent = '';
      if (!video) await setupCamera();
      if (!model) await loadModel();
      running = true;
      document.getElementById('status').textContent = '推論中…';
      requestAnimationFrame(loop);
    }

    function disposeAll() {
      stop();
      if (model) { model.dispose(); model = undefined; }
      if (video && video.srcObject) {
        for (const track of video.srcObject.getVideoTracks()) track.stop();
        video.srcObject = null;
      }
      tf.engine().disposeVariables();
      tf.backend().dispose?.();
    }

    document.getElementById('startBtn')?.addEventListener('click', start);
    document.getElementById('stopBtn')?.addEventListener('click', stop);

    (async () => { await selectBackend(); /* 自動開始したい場合は↓有効化 */ /* await start(); */ })();
    window.addEventListener('pagehide', disposeAll);
    window.addEventListener('beforeunload', disposeAll);
  </script>
</body>
</html>
